---
layout: post
title: Zenodo Machine Learning
tags: "software,zenodo,doi,github"
github: "https://www.github.com/vsoch/zenodo-ml"
categories: software
snippet: "code from ~10K Zenodo software repositories"
editable: software
---

{% include toc.html %}


## Summary

The [Zenodo-ML]({{ page.github }}) dataset is a collection of just under 10K records from the 
<a href="https://zenodo.org" target="_blank">Zenodo</a> service for generation of digital object identifiers (DOIs) 
for software and associated digital resources. In human terms, this means that someone writes a codebase for 
their software, and links it to Zenodo so others can find and cite it. For this dataset, it means that we can
find these codebases, and do the following:

 - convert each script file into a set of 80x80 images, with characters converted to ordinal, for use with machine learning
 - generate a file hierarchy tree for graph analysis
 - extract complete metadata like domain, authors, and description for the software


### What can I learn from this dataset?
Here are some analysis ideas to get you started! These are questions that we at Research Computing are interested in and working on, but we can't do it alone. We want to empower you to help!


#### Software in the Context of Image Analysis
First, let me give you a high level view of how this data can be understood.
Software, whether compiled or not, is a collection of scripts. A script is a stack of lines,
and you might be tempted to relate it to a document or page in book. Actually, I think
we can conceptualize scripts more like images. A script is like an image in that it is a grid
of pixels, each of which has some pixel value. In medical imaging we may think of these
values in some range of grayscale, and with any kind of photograph we might imagine having
different color channels. A script is no different - the empty spaces are akin to values of zero,
and the various characters akin to different pixel values. While it might be tempting to use
methods like Word2Vec to assess code in terms of lines, I believe that the larger context of the
previous and next lines are important too.

This project aimed to:

 1. Identify a corpus of scripts and metadata (Zenodo "software" bucket)
 2. Preprocess to derive images, metadata, and structure trees from the data
 3. Generate features of the scripts, or make associations between metadata and script content with deep learning.


#### Interesting Questions
Here are some ideas for questions that this dataset could help answer:

 - **comparison of software**: it follows logically that if we can make an association between features of software and some meaningful metadata tag, we can take unlabeled code and better organize it.
 - **comparison of containers**: in that our "unit of understanding" is not an entire container, if we are able to identify features of software, and then identify groups of software in containers, we can again better label the purpose / domain of the contianer.
 - **optimized / automated script generation**: If we have features of software, the next step is to make an association between features and what constitutes "good" software. For example, if I can measure the resource usage or system calls of a particular piece of software and I also can extract (humanly interpretable) features about it, I can use this information to make predictions about other software without using it.


### Generation

The dataset was generated by querying the Zenodo API for records, downloading the records archived code (a compressed archive and falling back to the original Github repository) and then running a script to process the scripts into 80x80 images, generate a file hierarchy tree, and save each repository into several data formats for your use. This process was run in parallel on a SLURM cluster at Stanford (Sherlock), and would also be possible to run locally (albeit it would take much longer!) For both cases, if you want to re-generate the dataset or update with newer records, the process is completely reproducible with the code that is provided in the <a href="{{ page.github }}">Github repository</a>. This page will review assumptions and details about the processing, and instructions for obtaining and using the dataset. 


### Assumptions

 1. We use an "image size" of 80 by 80, under the assumption that the typical editor / programming language prefers lines of max length 80 (see Python's Pep8 specification) and most machine learning algorithms prefer square images.
 2. We filter the files down to those less than or equal to 100,000 bytes (100KB --> 0.1 MB). This still leads to having on the order of a few thousand images (each 80x80) for one small script.
 3. We filter down the Zenodo repos to the first 10K within the set of the bucket called "software."
 4. I filtered out repos that (were strangely common) related to something to do with "gcube."
 5. We take a greedy approach in parsing files - in the case that a single file produces some special error, we pass it in favor of continued processing of the rest.


<br><br>

<hr>


## Tutorial

### Download Data
We will provide instructions here when we figure out how to serve this dataset! Right now it's living on the Sherlock Cluster, and is about half a terabyte for 10K code repositories.

### Loading Data
Let's take a look at the contents of one of the subfolders under folder:

```bash
tree data/1065022/
    metadata_1065022.pkl    
    images_1065022.pkl    
    images_1065022.h5 
```

The filenames speak for themselves! Each is a python pickle, but since pickles are fragile to python
versions, the data is provided in h5 format. We are providing pickles regardless because we will
provide a container with the proper python versions for loading it, and the more complicated h5 format
is a backup of sorts, and of course the entire generation can be reproduced if these data structures
fail. The file `images_*.pkl` contains a dictionary data structure
with keys as files in the repository, and each index into the array is a list of file segments.
A file segment is an 80x80 section of the file (the key) that has had it's characters converted
to ordinal. You do this in Python as follows:

```python
#  Character to Ordinal (number)
char = 'a'
number = ord(char)
print(number)
97

# Ordinal back to character
chr(number)
'a'
```

Here is how you would load and look at an image.

```python
import pickle

image_pkl = os.path.abspath('data/1065022/images_1065022.pkl')
images = pickle.load(open(image_pkl, 'rb'))
```

Remember, this entire pickle is for just one repository that is found in a record from Zenodo! If you
look at the images "keys" you will see that each one corresponds to a file in the repository.

```python
images.keys()
```

It follows, then, that if we index images for a particular key, we are going to find images! Specifically,
we will find a giant list of 80x80 images, where each image is a 2D numpy array with characters converted
to ordinal (as we showed above).

**more coming soon!**


### Other questions?
Thanks for reading! If you have other questions, or want help for your project, please don't hesitate to <a href="{{ post.github }}">reach out</a>.
